---
title: "paleofire: an R package to analyse sedimentary charcoal records from the Global Charcoal Database to reconstruct past biomass burning"
author: 'Blarquez et al. 2014'
output:
  html_document: default
  pdf_document: default
bibliography: paleofire-paper.bib
---


We describe a new `R` package, `paleofire`, for analysis and synthesis
of charcoal time series, such as those contained in the Global Charcoal
Database (GCD), that are used to reconstruct paleofire activity (past
biomass burning). `paleofire` is an initiative of the Global Paleofire
Working Group core team (www.gpwg.org), whose aim is to encourage the
use of sedimentary charcoal series to develop regional-to-global
syntheses of paleofire activity, and to enhance access to the GCD data
by providing a common research framework. Currently, `paleofire`
features are organized into three different parts related to (i) site
selection and charcoal series extraction from the GCD; (ii) charcoal
data transformation; and (iii) charcoal series compositing and
synthesis. We provide a technical description of `paleofire` and
describe some new implementations such as the circular block bootstrap
procedure. We tested the software using GCDv3 data from eastern North
America, and provide examples of interpreting results of regional and
global syntheses.

charcoal, fire, biomass burning, databases, `R` statistical language

Introduction
============

In the last decade, regional and global syntheses of sedimentary
charcoal records have been used to examine broad-scale patterns in
palaeofire activity [@Carcaillet2002; @Power2008; @Daniau2012]. The
linkages among fire, climate, vegetation and humans at
centennial-millennial timescales have likewise been examined using
global and regional syntheses [@Marlon2008; @Ali2012]. Syntheses of
charcoal records can also aid the validation and calibration of fire
simulations [@Flannigan2001; @Pechony2009; @Girardin2013; @Brucher2014].
Because fire influences ecosystems at all spatio-temporal scales
(ranging from days to centuries and from microsites to biomes), a
growing interest in paleofire research has emerged. Additionally, future
wildfire regimes may have no analogues from recent decades, and so
identifying reference conditions and baselines in the past has become
crucial to projecting future wildfire activity [@Girardin2013].
Sedimentary charcoal series from individual sites are distributed
worldwide, and are increasingly included in the Global Charcoal Database
[@Power2010 GCD], which provides the scientific community a global
charcoal dataset for research and archiving for sedimentary records of
fire (the GCD is available at <http://gpwg.org/gpwgdb.html>). Syntheses
of spatio-temporal changes in fire at global
[@Marlon2008; @Power2008; @Daniau2012; @Marlon2013] and regional
[@Marlon2009; @Mooney2011; @Vanniere2011; @Power2013] scales were
obtained by applying several analytical steps implemented by a set of
Fortran programs (Bartlein, P. J. unpublished). Because these
statistical methods are not easily usable or modifiable, the Global
Paleofire Working Group core team has developed a package using the
open-source `R` statistical programming language. The new package should
increase accessibility to paleofire data while providing the
fire-science community with new analytical tools that include and extend
the previously used functions for GCD data extraction and statistical
analysis.\
The aim of this paper is to describe the `paleofire` `R` package that
facilitates the analysis of charcoal records contained in the GCD. The
`paleofire` package functions are organized into three parts: (i) GCD
site selection and data extraction using a variety of criteria
(geographic, sedimentary, etc.), (ii) charcoal data transformation,
including re-scaling, single-record variance homogenization and
nonparametric trend estimation and (iii) data synthesis, including
confidence limit estimation using resampling procedures.

Global Charcoal Database to paleofire data synthesis
====================================================

The `paleofire` package works in conjunction with the `GCD` `R` package
that contains a simplified version of the charcoal dataset in order to
accommodate the different update frequency between the `paleofire`
package (frequent updates) and the Global Charcoal Database (infrequent
updates). The `checkGCDversion()` function can be used to determine
whether the `GCD` data package is current. If it is not, the function
asks whether the user wants to update the data. The minimal package
version numbers required for running the examples presented in this
study are 1.1.3 and 3.0.3 for the `paleofire` and `GCD` packages
respectively. Backward compatibility will be ensured from these
versions.\
As of , the GCD v3.0.3 contains a total of 736 charcoal records and is
provided as a Microsoft Access database available at <http://gpwg.org>.
The `GCD` data package is a simplified and reduced version of the GCD
database. The package consists of two data frames containing site
metadata and charcoal data. The two data frames combine several tables
from the GCD in order to simplify analysis in `R`, and exclude
chronology development information, such as radiocarbon dates; these
will likely be added however in future releases. Although most analyses
in `paleofire` may use data directly from the dataframes in the `GCD`
package, it is also possible to analyze user-defined database extracts
or other charcoal series not in the database using the pfAddData
function. There is currently no mechanism for permanently adding data to
the GCD package automatically; interested contributors should contact
the GPWG instead. The site metadata is accessible by typing the
`data(paleofiresites)` command at the `R` prompt. This data frame
provides a unique identifier for each site in the id\_site column and
associated metadata such as chronological, sedimentary or geographical
information.

The raw charcoal data are accessible with the `data(paleofiredata)`
command. The data consist of a seven column data frame containing: (i)
site unique identifier, (ii) sample depth, (iii) sample age, (iv) sample
charcoal value, (v) sample charcoal unit, (vi) extraction method (sieved
charcoal, pollen slide charcoals, etc.) and (vii) sample type unit
(influx or concentration). The default setting for the `R` package is to
select the preferred units (e.g., concentration or influx values are
typically preferred over charcoal-to-pollen ratios if both are
available) used in previous analysis [see @Daniau2012 or; @Power2008],
however `paleofire` allows one to analyse charcoal records with
user-defined units or methods (e.g. sieved *vs* pollen slide charcoals,
see pfSiteSel and pfTransform functions help for details).

Technical description of `paleofire`
====================================

Here we provide a technical description and several illustrative
examples of `paleofire`. The `paleofire` package is written in the `R`
scientific computing language (`R` Development Core Team, 2011) and was
developed under the `R` 3.0.3 version but remains compatible with
`R` \>=2.10.0. The functions in `paleofire` are arranged into three
groups associated with data selection, charcoal series transformation,
and synthesis. We used the S3 method scheme to implement generic
plotting and summary functions.

To present some of the `paleofire` capabilities, the examples below use
charcoal series from Eastern North America. For additional examples and
a detailed overview of individual functions, the reader is referred to
the online help available at
<http://cran.r-project.org/web/packages/paleofire/paleofire.pdf>.

Site selection
--------------

Two functions are dedicated to site selection. The first one,
`pfInteractive` requires users to interactively draw a polygon on a map
to select sites with respect to their geographic location. The function
returns a list object containing site names and identifiers that is
further used in the following analysis steps and is called using
`pfInteractive()`.

```{r}
install.packages('paleofire”,repo=“http://cran.r-project.org')
library(paleofire)
```


The `pfSiteSel` function is more versatile than `pfInteractive` and has
arguments for a variety of user-defined criteria. In the example below
we select charcoal series between 30° and 90° latitude and -100°
and -50° longitude, and include only those with at least one
geochronological (^14^C or ^210^Pb dating, tephra layer, etc.) control
point each 2500 year.

```{r}
ID <- pfSiteSel(lat>30 & lat<90, long>-100 & long<(-50), date_int<=2500, num_version<400) 
length(ID$id_site)
```


Seventy-one sites are selected and stored in the ID object of the class
`pfSiteSel`. The summary function associated with the `pfSiteSel` object
returns a table (Table SI1) containing site information, including
geographic (latitude, longitude and elevation) and chronological
descriptors (number of chronological control points, number of samples,
minimum and maximum estimated ages). In the example below the `summary`
function is applied to the ID object and the `pfSiteSel` function is
used to select site records with at least 20 samples.

```{r}
sumID <- summary(ID)
ID <- pfSiteSel(id_site %in% ID$id_site & num_samp>=20)
length(ID$id_site)
```


The 57 selected sites can be plotted on a map using the generic `plot`
function ; a zoom level can be specified using the zoom argument. The
use of this function is illustrated in the example below, which is used
to construct Figure 1. The `plot` function may also be used to explore
the sampling resolution of sites using the `type=chronology` argument.

```{r}
plot(ID, zoom="world")
```


Data transformation
-------------------

Charcoal values contained in the GCD can vary widely among and within
sites due to multiple factors. For instance, variations in (absolute)
charcoal abundances can be related to different analytical methods [i.e.
sediment treatment; @Tinner2003] as well as to unique physiographic site
characteristics @Marlon2006. Variations in charcoal values may also be
linked to differences in the types of records [pollen slide charcoals,
sieved charcoals, charcoal/pollen ratios, @Carcaillet2001a]. Lastly,
differences in the original sample quantities (influx, concentration,
percentage) could also contribute to variations in charcoal values.
Consequently, transformation and standardization of different charcoal
records is a highly recommended step in generating a synthesis. A
methodology to standardize charcoal records was proposed by @Power2008
and involved a three-step data transformation including a minimax
data-rescaling, variance homogenization using @Box1964 data
transformation, and a final rescaling to Z-scores. Using the
`pfTransform` function these transformations are done on influx using
the following command:

```{r}
TR1 <- pfTransform(ID, method=c("MinMax","Box-Cox","Z-Score"))
```


Note that by default the `pfTransform` function calculates influx for
series whose data is given in concentrations, by multiplying
concentrations by sediment vertical accretion rate ($cm.yr^{-1}$)
calculated using the age-depth model for each record (the
`QuantType=NONE` argument can be passed to the `pfTransform` function
for keeping original units but it is not recommended). The `method`
argument may list single or multiple methods (that are computed in the
same order as given in the function), relating to charcoal data
transformation or smoothing. The distributions of charcoal values
typically have long right tails, and can generally be easily transformed
to a symmetrical “normal”-like distribution @Higuera2011. The
transformations we implemented include both the @Box1964 parametric
power transformation technique (default method) and the modified Box-Cox
modulus transformation, proposed by @John1980, which is known to more
effectively produce normality in long tailed data, i.e. in the case of
charcoal series data presenting numerous zero values. These are
accessible through the pfTransform function using the
`type=c(BoxCox1964 , JohnDraper)` argument.

The types of filtering (smoothing or compositing) techniques implemented
here include running means, median, min, max, quantiles, locally
weighted scatter plot smoother (LOESS) and smoothing splines; all these
methods take an additional parameter giving the window width for
computations (RunWidth argument) or the smoothing parameter in the case
of the LOESS or the smoothing-spline methods (span argument). Associated
to `pfTransform` users may choose to add their own data to the analysis
using the `pfAddData` function that uses the CharAnalysis file type
format @Higuera2009 [freely available at
<https://github.com/phiguera/CharAnalysis>], or any file containing
charcoal quantities and associated depth and age information as input.
In the following example we will add the charcoal data from @Senici2013.
The `BasePeriod` argument is used to set the period 200-4000 BP as a
base period for the Z-score calculation [@Power2008]. Note that a
minimax data-rescaling step was added after the Box-Cox transformation
because Box-Cox transformed series are comparable only if they share
identical $\lambda$ values [@Marlon2008].

```{r}
## Add Ben lake and Small lake data to the 
# analysis (Senici et al., 2013) 
download.file(url="http://blarquez.com/public/data/data_cageo.zip", 
                destfile="data_cageo.zip")
unzip("data_cageo.zip")
mydata=pfAddData(files=c("Ben.csv","Small.csv"), 
                   metadata="metadata.csv", type="CharAnalysis")

## Transform:
TR2 <- pfTransform(ID,add=mydata,BasePeriod=c(200,4000),
                   method=c("MinMax","Box-Cox","MinMax","Z-Score"))
## Delete downloaded files
file.remove(c("Ben.csv","Small.csv","data_cageo.zip","metadata.csv"))
```

Data synthesis and compositing
------------------------------

Synthesizing or compositing charcoal series typically involves pooling
the different series in order to calculate the mean charcoal value
(across sites) at each time step. This simple operation could be
performed in different ways using the `pfComposite` function.
Alternatively, a data-binning procedure can be used to calculate a
composite curve. The binning sequence must be supplied in order to allow
the `pfComposite` function to calculate the mean charcoal value for each
series within each binning interval and then calculate the mean for all
series. This can be achieved using arbitrary 500-year bin widths:

```{r}
COMP1 <- pfComposite(TR2, binning=TRUE, 
                     bins=seq(from=0,to=11000, by=500))
```



This approach (`pfComposite`) is equivalent to @Power2008 but
`paleofire` also implements the methods proposed by @Marlon2008 and
@Daniau2012, which consists of a two-stage smoothing method
(`pfCompositeLF`). The procedure implemented in the package was slightly
modified compared to @Marlon2008 but returns highly comparable results
(see SI for details). The two-stage smoothing method first “pre-bins”
individual charcoal series using non-overlapping bins in order to ensure
that records with high sample resolution do not have a disproportionate
influence on the composite record, and that data will be not
interpolated for records with a lower resolution. The second step
smooths the pre-binned series using a locally-weighted scatter plot
smoother “LOWESS” [@Cleveland1979] with a pre-defined constant bandwidth
(half-width) given in the years (`hw` argument). In the following
example we will pre-bin the data with 20 year non-overlapping bins and a
LOWESS smoother with a 500 year window half width (i.e., a 1000-year
smoothing window).

```{r}
COMP2 <- pfCompositeLF(TR2, tarAge=seq(-50,12000,20), 
                       binhw=10, hw=500, nboot=100)
```


The `tarAge` argument is used to define the center of each bin in the
prebinning procedure (`binhw` being the prebinning bin half width) and
the ages where the LOWESS estimation takes place.

Confidence intervals
--------------------

*Option A*\
The confidence intervals for the `pfComposite` function are calculated
by bootstrap resampling of the binned charcoal series and calculatiion
of the mean for each bin n times, using the argument `nboot` to choose n
value (by default nboot=1000). For the `pfCompositeLF` function
confidence intervals are calculated by bootstrap resampling the
prebinned series (as opposed to individual samples) and then applying
the LOWESS curve fitting. This operation is repeated n times and is
defined using the argument `nboot`. The confidences intervals are
estimated based on the distribution of the bootstrap replicates.

Objects of the class `pfComposite` and `pfCompositeLF` can be plotted
using the generic `plot` function. Confidence intervals are specified
using the `conf` argument. The `add=sitenum` plot function argument can
be used to display the number of charcoal sites contributing to each
composite value at each time step (Figure 2).

```{r}
par(mfrow=c(2,1))
plot(COMP1,conf=c(0.025,0.975),main="(a)")
plot(COMP2,conf=c(0.05,0.95),main="(b)")
```

![Composite charcoal series for North Eastern American sites. (a)
Composite values and associated confidence intervals using the
pfComposite function. (b) Composite values and associated confidence
intervals using the pfCompositeLF function (b). Dashed lines correspond
to the 97.5th, 2.5th and 95th, 0.5th percentiles
respectively.]

*Option B*\
Bootstrapped confidence intervals are usually calculated by resampling
the charcoal series with replacement in order to test the sensitivity of
the composite record to individual series (or sites, option A). However,
because the values in charcoal series are autocorrelated, testing the
significance of their temporal variations is not straightforward. Block
bootstrap has been proposed to test the significance of changes in
stationary time series [@Kunsch1989]. Here we implemented a new
procedure in the `paleofire` package of “moving” or “circular” block
bootstrap, which consists of splitting each charcoal series into $n-b+1$
overlapping blocks of data, where $n$ is sample size and $b$ the block
size. These blocks are randomly selected (with replacement) to
reconstruct new individual charcoal series that are in turn used to
estimate the confidence intervals around the charcoal series composite
mean. This procedure may dampen the long-term trends in data,
particularly if individual sites record opposing trends. If the observed
trend does not exceed the confidence intervals, then there the composite
values at that time are not greater than by chance if records are not at
all synchronized. However, a composite curve not exceeding the
confidence intervals does not exclude the occurrence of important trends
in the composite series. This procedure is rather used for testing the
significance of local minima or maxima in the composite time series.\
The optimal block size for a given series is given by:
$b=2\times(-1/log(\rho))$, where $\rho$ is the lag one autocorrelation
coefficient of that series [@Adams2003].

The circular block bootstrap method is commonly used in Superposed Epoch
Analysis, a compositing technique that aims to find the response of a
variable to one or multiple particular events, for instance insect
outbreaks [@Nola2006 e.g.] or fires [@Swetnam1993 e.g.] using
dendrochronological series or paleoecological proxy series
[@Blarquez2010a]. The `R` implementation follows the Matlab SEA function
available at <http://blarquez.com> that was inspired by @Adams2003
methodology. The `pfCircular` function is called using the following
command and returns an object of class `pfCircular` that can be plotted
using the generic plot function:

```{r}
circboot <- pfCircular(COMP1, b=NULL, nboot=100,
                        conf=c(0.005,0.025,0.975,0.995))
plot(circboot)
```


![Composite mean of charcoal series for Eastern North American sites
(black line) and associated confidence intervals estimated using a
circular block bootstrap procedure (dashed lines). Dashed lines
correspond to the 99.5th, 97.5th, 2.5th and 0.5th bootstrapped
percentiles, respectively.]

The `b=NULL` argument indicates that the block size is automatically
calculated for each series using the formulation above.

Results interpretations
=======================

On figure 2, we see that before c. 10,500 cal BP, the two approaches
(simple binning and LOWESS fitting) give different results. Because the
`pfCompositeLF` used a local regression approach with a bandwidth of
1000 years, composite edges (-50-1050 and 11000-12000 cal BP periods)
may suffer from bias (edge effect), however this bias should be minimal
here and reducing his effect does not change the results significantly
(results not shown of for an application of the minimum-slope correction
approach of @Mann2004 [@Mann2008], which is implemented in the
pfCompositeLF function, see the help for usage details). Additionally
the number of sites contributing to the overall composite curve before
10,500 cal BP is low ($<$ 30 sites) and thus the curve should be
interpreted with caution. The period from 10,500 to 8000 cal BP and from
c. 200 cal BP to present, displays large positive anomalies in composite
values for both approaches. On Figure 3 we see that the positive
charcoal composite anomalies during the period 9000-10 000 cal BP and
negative ones during the periods 6000-7000 and 10,500-12,000 are
significantly different from a 12,000 year linear trend and exceed the
95th confidence interval range given by the circular block bootstrap
procedure (Fig 3). However, large classical (site resampling based)
confidence intervals during the 10,500-12,000 cal BP period indicate
that the response is not homogeneous among the charcoal series (Fig
2a-b). The negative composite values at 6000-7000 cal BP are associated
with confidence intervals that are narrower compared to previous periods
indicating that the within-sites response is relatively homogeneous and
thus likely related to forcing factors occurring at a broad spatial
scale (e.g. climate).

Conclusion
==========

We have presented the `paleofire` package that allows the paleofire
community to easily interrogate data contained within the Global
Charcoal Database and to perform the analytical steps required to
produce a regional charcoal synthesis using a few simple commands. The
`paleofire` package introduces some new analyses such as the circular
block-bootstrap procedure and various new charcoal data-transformation
techniques and background-estimation procedures. The package also
provides an integrated research framework linking the GCD to the
open-source `R` statistical language. The implemented features are
likely to be extended by future releases and new implementations that
will increase `paleofire` capabilities, such as spatio-temporal
clustering, which is currently in development. The stable release of
`paleofire` is available from the CRAN website but users may choose to
test development releases from Git
(<https://github.com/paleofire/paleofire>). We hope `paleofire` will be
of broad interest to fire scientists and ecosystem managers, and we
encourage its use to perform original research and welcome any
development requests and feedback.

Acknowledgements
================

We wish to thank all data contributors to the GCD, PAGES workshop
funding, the UMR Chrono-Environnement, the University of Franche-Comté
and the Région of Franche-Comté for supporting the Global Paleofire
Working Group workshop in Frasne (October 2013). OB was supported by a
postdoctoral grant from the Fonds Québécois de la Recherche sur la
Nature et les Technologies and the FONCER program. JM was supported by
NSF grant EF-1241870.

References
==========




